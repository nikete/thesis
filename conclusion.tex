\chapter{Conclusion}
\label{cha:conc}

We provide a summary of thesis and discuss future directions in which to extend this work in in Section~\ref{sec:future}.

%When learning, it can be useful to look not only at our recommendations, but also how those recommendations were carried out by others. This is the case even when our incentives and those of others involved are perfectly aligned. 

The first part of the thesis introduced compliance information into the bandit setting. 
Compliance information reflects the choice actually taken by the subject, rather than the algorithm's recommendation. 
In many cases compliance information can be used to accelerate learning.
Further, for situations where the number of arms is large relative to the number of time steps, and the subject's non-compliance is towards the higher reward arms, compliance awareness can make learning possible in problems where otherwise it is not. 
However, naively incorporating compliance information leads to algorithms with linear regret, as seen in Example~\ref{eg:rich}. 
We have therefore developed hybrid strategies that are the first algorithms that incorporate compliance information while maintaining a worst-case guarantee. 

The second part of the thesis studied the elicitation of information from self interested experts for decision making.
For the single decision case, which had previously been analyzed in the decisions market literature, we introduce the first mechanism for multiple experts with a good ex-post Nash equilibrium that preserves freedom.
It achieves incentive compatibility for the experts without requiring randomized strategies with full support from the subject, as previous mechanisms do. Further, entry into the mechanism has positive expectation for both useful experts and subjects.
We also introduced the first model for the repeated case, which generalizes both one shot multi-expert elicitation and contextual bandit models.

%several smaller contributions
%the recycling trick in chapter 2
%To the best of our knowledge, the use of such over-represented signals spaces in mechanism design (that is using a report space that is strictly bigger than the signal type space) is novel, through the literature is vast, and it seems like a natural idea once the mechanism does not have access to the prior (if there is access tot he prior the mechanism can simply).


%Compliance information will arise whenever bandit algorithms provide recommendations to humans, suggesting the setting will be of increasing importance in future. An important open problem is to characterize the \emph{advantage} that hybrid algorithms have over algorithms using the \chosen\, protocol, as a function of the structure of the compliance behavior. It is also likely that the algorithms proposed here are far from optimal in the finite setting, and that there is room to improve upon their performance.
% One obvious place is by plugin in more sophisticated baseline algorithms, cite Thor optimally confident UCB. 
%Note that in the asymptotic regime, these algorithms are basically optimal  ?

\section{Future Work} \label{sec:future}
\subsection{More Practical Mechanisms for the one shot setting}

While many decision do repeat themselves with new subjects, including those that motivate most papers in the one shot decision market literature , others are more unique. 
The crucial problem is to estimate the counter-factual reward obtained had a different action been taken.
Some form of peer elicitation seems inevitable, but it is unclear how to combine this with the signal aggregation aspects of optimal decision advice that are embodied by the bidding mechanism. 


\subsection{Generalization}

The final model explored in the thesis has the settings described in the previous two chapters as special cases.
The bandit model has a vast range of extensions and special cases in which more specialized algorithms can make substantial advantage. It is interesting to consider the self-interested experts variations of those settings and see if more specialized mechanisms can also do better.



Natural directions for further generalization beyond our final model are:

\begin{enumerate}

\item Settings with more supervision. Prediction markets and learning from expert advice are tightly connected. Bandit algorithms and repeated advice elicitation can be seen as two potentially complementary sources of information to aid decisions. However, the two connections are quite different. It could be valuable to extend feedback graphs and other notions that interpolate between the bandit and full supervision settings to take into account incentivized experts as in our model. 

\item Incorporating general sources of information that are observed after the action has been chosen by the algorithm. Compliance has a very specific structural relation to the arms selected. It is interesting to explore what can be said generically about what structure the information has to have to be potentially useful to incorporate even when it arrives along with the reward.

\item Costly signal acquisition. It is natural to consider a situation in which experts' signals are costly for the experts to acquire. How can the scale of the rewards that are shared be optimally chosen?

\item Learning valuation functions from bid and signal data. Our mechanism in chapter 5 faces a severe limitation in what signal structures support truthfulness when it does not know the value function of experts. Is it possible to learn the value functions from previous bid and signal reports?

\end{enumerate}

% A Nash Bayes analysis of the final proposed mechanism might also be interesting.
% Proxy mechanisms, where each agent fully reveals their signal to a intermediate regret minimization algorithm, and when all regret minimization algorithms representing the various agents together can converge faster on the optimal solution in the style of \cite{syrgkanis2015fast}



% % 2050 vision: 

