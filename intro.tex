\chapter{Introduction}
\label{cha:intro}


\quote{\textit{
	That thing is called free, which exists solely by the necessity of its own nature, and of which the action is determined by itself alone. On the other hand, that thing is necessary, or rather constrained, which is determined by something external to itself to a fixed and definite method of existence or action.}}{-- Spinoza, Ethics, Part I, Definition VII}
%TODO bob marks this but does not comment

\section{Thesis Statement}
\label{sec:thesisstatement}

A decision maker's freedom has both positive and normative implications for the design of learning algorithms and mechanisms that seek to improve decisions.
Positively, incorporating awareness of subject freedom can improve the performance of learning algorithms for decision problems, relative to those which do not take it into account.
Normatively, it motivates maintaining subject freedom as a design criterion in the design of mechanisms for decision making.

\section{Problem Statement}
\label{sec:problemstatement}

One can learn to decide from experience or from the advice of others. Consider the following two situations:

\begin{enumerate}
	\item An algorithm seeks to help a doctor facing a sequence of patients for which there is an established and a novel treatment.
	\item Patients seek to elicit information from experts to select the optimal treatment for their condition.
\end{enumerate}

In both situations it is natural to assume that the patients have the last say on what treatment they take.
In a more abstract sense the \emph{subject} who takes the action and lives through its consequences retains their freedom; their actions are not externally determined by the system which helps to inform them.
\emph{Maintaining freedom} for the subject in decision support thus implies that the actions the system suggests need not be those the subject takes.

These two motivating interaction patterns, ignoring considerations on the subject's freedom, are found reflected in two previously separate parts of the literature: the first is the classic bandit setting (introduced in \citep{thompson:33}); the second is the more recent and relatively obscure literature on decision markets \citep{berg2003prediction,hanson2002decision,othman2010decision,boutilier2012eliciting,chen2014eliciting}). In both it is widely assumed that the action selected by the algorithm or mechanism is the one carried out by the subject.
%TODO it is not clear to me from the two given example situations which patterns you mean. maybe spare a sentence to explain the connection to bandits and decision markets respectively. you might even want to explain the bandit and decision markets.

This is implicit in most of the bandit literature, where no variable encodes the potential distinction between the algorithm's and the subject's choices of actions; rarely consideration is given to the possibility that they can differ. Incentive-compatible bandits \citep{kremer2014implementing,mansour2015bayesian,mansour2016bayesian} are a noteworthy exception.

The subject's follow-through of the algorithm's or mechanism's selected action is explicit in the decision market literature. Those mechanisms based on sequential proper scoring rules contingent on the action taken (voiding the markets contingent on the actions not taken) require not only that the subject follow the mechanism's choice, but select ex-post dominated actions with positive probability to incentivize experts.

Operationally, in the bandit setting, our notion of the subject's freedom can be captured by considering, in addition to the usual variable which encodes the action that the algorithm or mechanism selects, a second variable for the action that the subject actually takes. Naively using such a variable and simply replacing the chosen with the observed action (in a standard worst case sub-linear regret algorithm) leads to linear regret in the worst case.
%TODO give outlook on the non-naive approach you will take, or delete the last sentence

In the mechanism design problem of expert elicitation for decision making, maintaining freedom rules out classes of mechanisms that rely on the subject taking dominated actions with positive probability. Previously, no mechanisms that are incentive compatible with many experts where the subject retains its freedom (is not knowingly required to take an ex-post dominated action with positive probability) were known \citep{othman2010decision,chen2014eliciting}).



\section{Freedom: Subject as Principal for Decisions with no Externality}

This thesis takes freedom of subjects as a design criterion and seeks to further the understanding of how to incorporate it into the  algorithms and mechanisms where it is relevant.
The natural setting where this is a good design criterion is actions that only affect a single agent (the \emph{subject}) who both carries out the action and receives the reward.
Motivated by Spinoza Ethics' Definition VII that opens this chapter, we define the subject as free if the subject's action is not determined by the output of the algorithm or mechanism.
%TODO format that spinoza citation properly. also, i changed the definition to something i find more clear, please check if you agree.

In the bandit setting, preserving the freedom of the subject requires that the algorithm does not directly control the action taken.
This opens the possibility that the algorithm's choice of action for a round is different from the action the principal carries out.

In the work on the normative implications for incentive schemes used in part II we assume a utility maximizing principal; mechanisms that retain their freedom allow them to pick the action that maximizes their utility.
In the decision market mechanisms previously proposed in the literature, incentive compatibility of the max decision rule for the experts necessitates \citep{othman2010decision,chen2014eliciting}) violating the freedom of the subject by dictating that the distribution of actions they take have full support. This rules out subjects that always take their optimal decision.
%TODO that citation seems to be in the wrong place in that sentence.


It is worth noting this design criterion clashes with other desirable ones, most notably the utilitarian objective of maximizing social welfare, where the principal is an abstract social planner who aims to maximize the sum over all agents' utility. This social welfare objective means that optimal mechanisms there \citep{kremer2014implementing,mansour2015bayesian,mansour2016bayesian} constrain the information set revealed to the subjects (e.g. the patient who is or is not taking the treatment at a given point in time for the clinical case).







\section{Decisions}

Decision making, as understood in this thesis, is concerned with selecting an action so as to achieve a favorable outcome.
Examples of such decision making problems are:

\begin{enumerate}
	\item  prescribing a treatment to a patient so as to maximize their quality adjusted life years.
	\item selecting which ad to display to a web user so as to maximize the probability the user will click on the ad.
	\item advising a company in which of some competing projects to invest in so as to maximize their profits.
\end{enumerate}

The literature on bandit algorithms was originally motivated by the first, and this also is the motivating application in this thesis. More recently, work within computer science has often had some variation of the second as the motivating application. The third has been the motivating application in the decision markets literature.

Decision problems can be contrasted with prediction problems.
In a prediction problem, the canonical example being weather forecasting, the performance of any strategy can be directly evaluated once the event of interest is realized.
In a decision problem, the performance of strategies that take actions different from those that were used is inherently counter-factual.

In the settings with a sequence of decisions we assume that a decision does not directly affect  future decisions. That is, while the underlying state of the system may be changing, the decisions do not affect its evolution.

In the expert elicitation for decision setting, we assume no inherent interest of experts on actions, nor any cost to them in acquiring their signals.
For example, the expert doctors offering advice have no conflict of interest and would not profit more from carrying out a specific treatment.
%TODO explain those settings...also mind the examiner comment on what will happen if they do have conflicting interest

\section{Learning}

We focus on two distinct sources of learning and their interaction.
First, as has been the focus in the machine learning literature on online learning, we consider learning from experience in a setting where a choice from a finite set of $K$ possible actions is sequentially repeated $T$ times.
Second, as is the focus in the decisions market literature, we consider learning from recommendations of a set of $N$ \emph{experts} who may have information about which of the $K$ actions is best in a given situation.


Taking into account the subject's freedom can make learning possible in settings where it is not without doing so.
A particularly relevant class of learning settings where this can be true and which arises naturally in personalized medicine and lifestyle interventions is when $K/T > 1$.

On the other hand, providing freedom to the subject can render mechanisms infeasible that seek to create the right incentives to learn from experts, by dictating the distribution over the $K$ actions that will take place.
In particular, all past incentive compatible mechanisms for $N>1$ experts have required that the distribution over the $K$ actions has full support.


\section{Games}

Algorithms for bandit problems have been much analysed within game theory.
This has largely focused on giving worst case guarantees that result from minimax analysis of zero sum games against an adversary.
Game theory plays an even more fundamental role in mechanisms for optimal decision elicitation such as decision markets, since equilibrium considerations and not just worst case concerns are inherent to the setting.
Our focus in the equilibrium based analysis is on the strategic aspects of the experts offering the advice, and we consider mechanisms.


%"It is well known that the ability of the mechanism to implement efficient outcomes for private value choice problems does not extend to interdependent value problems. When an agent’s type affects other agents’ utilities, it may not be incentive compatible for him to truthfully reveal his type when faced with VCG payment"s from "Implementation with interdependent valuations"

\section{Thesis Contributions}

We first turn to the purely learning theoretic implications of subject freedom, in learning from sequences of decisions taken by such free subjects.
This addresses the positive aspect of our thesis statement, by showing that awareness of the consequences of subject's freedom can improve learning.
If subjects have freedom, we should not assume that the actions an algorithm selects are those that are carried out in the world.
Valuable information can be learned from observing when that is the case, and what happens when it is not.
Formally, this is done by extending the bandit setting and to incorporate compliance information while preserving regret bounds. 
We present bandit algorithms that use compliance awareness and empirically outperform their standard variant, while preserving worst case regret guarantees up to multiplicative constants.
We then present empirical results from simulations using implementations of these algorithms.

We then turn to purely strategic considerations, focusing on the incentive structure for the elicitation of advice on an optimal action from multiple experts.
We take a normative stance, proposing preserving freedom for the subject as a first order design criterion for the mechanism. This implies that the mechanism can't have the subject take dominated actions.
We present mechanisms that can elicit decision information from multiple experts without committing to taking dominated actions with positive probability. We show sufficient conditions on the signal structure of the experts for incentive compatibility and efficiency.
The crucial conceptual contribution which enables this is a reduction to an auction with interdependent signals and valuations. 


Finally, we consider a natural setting that emerges from the combination of the above. A sequence of subjects make decisions, and each can receive advice from a fixed set of experts that the mechanism seeks to incentivize.
The model for this setting is extremely general, having as special cases standard, compliance aware and contextual bandits, as well as decision markets.
We show that in natural information structures the repeated sequential use of the single-agent multi-expert mechanism fails to explore or aggregate information efficiently.
We present a simple and practical market structure that incentivizes exploration, information revelation and aggregation with selfish experts, while maintaining subject freedom. We then briefly consider some of the limitations of this simple mechanism.


\section{Scope}

When we focus on incentive compatibility, we do so for the experts, not the subject.
Assuming a utility maximizing subject -- one that uses the max decision rule -- restricts the freedom of that subject.
For example, having unstable preferences that will change once the mechanism commences brings both limits and possibilities.
While it limits the richness of the mechanics we can use (since we need to account for a subject that may or may not respond to incentives), it also liberates the analysis from constraints created by assuming all subjects are rational.
For example, in bayesian  exploration \citep{mansour2015bayesian}) there are priors over arms rewards where some arms are never explored, even through they may be optimal with positive probability \footnote{They might even be optimal with a probability of almost one half}. The possibility of some share of agents not being utility maximizers means the mechanism can explore such arms.
%TODO one examiner thinks this needs more explanation.

While the direct decision elicitation mechanism we propose sidesteps the main problems of previously proposed mechanisms, it makes very strong use of a common prior assumption that extends over both compliance probabilities of subjects and a common prior probability distribution accross experts over their joint signals. This creates a tension with the canonical concern of Wilson (1987):
%TODO cite properly


\begin{quote}
Game theory has a great advantage in explicitly analyzing the consequences of trading rules that presumably are really common knowledge; it is deficient to the extent it assumes other features to be common knowledge, such as one agents probability assessment about another's preferences or information. I foresee the progress of game theory as depending on successive reductions in the base of common knowledge required to conduct useful analyses of practical problems. Only by repeated weakening of common knowledge assumptions will the theory approximate reality.
\end{quote}


This motivates our second mechanism, which retains the structure of the direct mechanism but replaces signals with bids. We analyze different information structures to understand when information can still aggregate appropriately in this setting.

The relation between the different settings considered in this thesis and in the literature is summarized in the table bellow.

\begin{table}
	\begin{tabular}{lllll}
		\toprule
		Setting & Subjects & Information & Solution Concept\\
		\midrule
		Forecasting & T  & past rewards for all actions & Minimax  \\
		Bandit & T  & past rewards &  Minimax  \\
		Peer Prediction & 1 & N strategic reports & BNE \\
		Prediction Market & 1 & N reports, full reward vector &  NE\\
		Decision Market & 1 & N reports, reward for action & NE  \\
		Advice Auction  & 1 & N reports, reward for action, taken action & NE  \\
		Compliance Aware Bandit & T  & reward for action and compliance & minimax \\
		N sided Advice Markets  & T  &  N  reports and rewards for actions & NE  \\
		\bottomrule
	\end{tabular}
	\caption{Relation between learning settings in the thesis and literature.}
\end{table}


\section{Publications and Collaborations}

Most of chapters 3 and 4 on compliance aware bandits appears in \citep{della2016compliance}. The work in Chapters 5 and 6 on decision elicitation from multiple experts has benefited from feedback of David Balduzzi.

During the course of the PhD I also collaborated on related publications in, prediction markets \citep{frongillo2012interpreting}, market making \citep{kinathil2014closed,kinathil2016symbolic}, crowdsourcing \citep{della2012crowd} and medical applications \citep{della2016out}.


\section{Thesis Outline}
\label{sec:outline}

In Chapter~\ref{cha:background}, we provide background about the two settings that this thesis makes contributions to. In Chapter~\ref{cha:bandit}, we present two novel classes of algorithms and associated regret guarantees that take into account the underlying freedom not to comply with an algorithm's chosen treatment. We then study the empirical performance  of these algorithms based on both synthetic and real data in Chapter~\ref{cha:empirical}.
In Chapter~\ref{cha:market}, we turn our attention to eliciting an optimal action, and offer the first incentive compatible algorithm for elicitation from multiple experts that does not restrict the agent's freedom. We show it to be optimal while exploring some of its practical limitations from its extensive use of a common prior, as well as what is lost when we move to a simpler mechanism that relies on bids instead of signals.
In Chapter~\ref{cha:twosided}, we present a novel setting with both multiple experts and multiple subjects that arrive sequentially, which we term \emph{two sided decision markets}. We propose an extension of the simple mechanism based on a sequence of second price auctions that internalizes the benefits of exploration, while rewarding only valuable experts.

%We then explore some  Chapter~\ref{cha:conclusion}.
